# üìö **Documenta√ß√£o Completa: Sistema de Importa√ß√£o MenuDino com Edge Functions**

## üìã **√çndice**

1. [Vis√£o Geral](#vis√£o-geral)
2. [Arquitetura do Sistema](#arquitetura-do-sistema)
3. [Diagrama de Sequ√™ncia](#diagrama-de-sequ√™ncia)
4. [Estados e Transi√ß√µes](#estados-e-transi√ß√µes)
5. [Estrutura de Dados](#estrutura-de-dados)
6. [Implementa√ß√£o T√©cnica](#implementa√ß√£o-t√©cnica)
7. [Fluxo de Opera√ß√µes](#fluxo-de-opera√ß√µes)
8. [Tratamento de Erros](#tratamento-de-erros)
9. [Monitoramento e Logs](#monitoramento-e-logs)
10. [Deploy e Configura√ß√£o](#deploy-e-configura√ß√£o)
11. [Testes e Valida√ß√£o](#testes-e-valida√ß√£o)
12. [Manuten√ß√£o e Troubleshooting](#manuten√ß√£o-e-troubleshooting)
13. [Considera√ß√µes Finais](#considera√ß√µes-finais)
14. [Refer√™ncias e Recursos](#refer√™ncias-e-recursos)

---

## üéØ **1. Vis√£o Geral**

O Sistema de Importa√ß√£o MenuDino √© uma solu√ß√£o que resolve problemas de CORS e otimiza o processo de importa√ß√£o de menus de restaurantes. O sistema utiliza Supabase Edge Functions para fazer scraping de websites MenuDino e armazena os dados extra√≠dos em uma tabela de logs, permitindo preview instant√¢neo e importa√ß√£o eficiente.

### **Problemas Resolvidos**
- ‚ùå **CORS Policy**: Bloqueio de requisi√ß√µes cross-origin
- ‚ùå **Reprocessamento**: Dados extra√≠dos m√∫ltiplas vezes
- ‚ùå **Performance**: Lentid√£o no preview e importa√ß√£o
- ‚ùå **Auditoria**: Falta de rastreamento de tentativas

### **Solu√ß√µes Implementadas**
- ‚úÖ **Edge Functions**: Scraping server-side sem CORS
- ‚úÖ **Cache Inteligente**: Dados salvos em `import_logs`
- ‚úÖ **Preview Instant√¢neo**: Carregamento direto do banco
- ‚úÖ **Importa√ß√£o Eficiente**: Uso apenas do ID de refer√™ncia
- ‚úÖ **Atualiza√ß√µes em Tempo Real**: Frontend recebe mudan√ßas via Supabase Realtime

---

## üèóÔ∏è **2. Arquitetura do Sistema**

```mermaid
graph TB
    subgraph "Frontend (React)"
        A[MenuImportPage] --> B[MenuDinoScraper]
        B --> C[Supabase Client]
        A --> D[Realtime Subscription]
    end
    
    subgraph "Supabase Edge Functions"
        E[scrape-menudino] --> F[Web Scraping]
        F --> G[Data Processing]
        E --> H[Database Operations]
    end
    
    subgraph "Database (PostgreSQL)"
        I[import_logs] --> J[restaurants]
        I --> K[categories]
        I --> L[dishes]
        I --> M[complements]
    end
    
    C --> E
    E --> I
    I --> D
    D --> A
```

### **Componentes Principais**

1. **Frontend (React + TypeScript)**
   - `MenuImportPage`: Interface de importa√ß√£o
   - `MenuDinoScraper`: Cliente de scraping
   - `Supabase Client`: Comunica√ß√£o com backend
   - `Realtime Subscription`: Recebe atualiza√ß√µes em tempo real

2. **Edge Functions (Deno + Hono)**
   - `scrape-menudino`: Fun√ß√£o de scraping
   - Processamento de HTML
   - Extra√ß√£o de dados estruturados
   - **Gerenciamento completo dos registros de importa√ß√£o**

3. **Database (PostgreSQL)**
   - `import_logs`: Tabela principal de logs
   - Tabelas de destino: `restaurants`, `categories`, `dishes`

---

## üîÑ **3. Diagrama de Sequ√™ncia Atualizado**

```mermaid
sequenceDiagram
    participant U as Usu√°rio
    participant F as Frontend
    participant EF as Edge Function
    participant DB as Database
    participant MD as MenuDino

    Note over U,MD: Fase 1: Inicializa√ß√£o e Cria√ß√£o do Log
    U->>F: Clica "Importar Menu"
    F->>EF: POST /scrape {url}
    EF->>DB: INSERT import_logs (status: 'pending')
    EF-->>F: {success: true, importLogId: 'uuid'}
    F->>DB: subscribe('import_logs', importLogId)
    
    Note over U,MD: Fase 2: Background Task de Scraping
    EF->>EF: Inicia background task
    EF->>MD: GET / (com headers apropriados)
    MD-->>EF: HTML Response
    EF->>EF: extractMenuData(html)
    EF->>DB: UPDATE import_logs (status: 'preview_ready', scraped_data)
    DB-->>F: Realtime update (status atualizado)
    
    Note over U,MD: Fase 3: Preview
    F->>U: Exibe preview dos dados (via subscription)
    
    Note over U,MD: Fase 4: Confirma√ß√£o
    U->>F: Clica "Confirmar Importa√ß√£o"
    F->>EF: POST /import {importLogId}
    
    Note over U,MD: Fase 5: Importa√ß√£o
    EF->>DB: SELECT scraped_data FROM import_logs
    EF->>DB: INSERT restaurants, categories, dishes
    EF->>DB: UPDATE import_logs (status: 'import_success')
    DB-->>F: Realtime update (status atualizado)
    F-->>U: Confirma√ß√£o de sucesso
```

### **Detalhamento das Fases**

#### **Fase 1: Inicializa√ß√£o**
- Usu√°rio inicia processo de importa√ß√£o
- Frontend chama Edge Function com URL
- Frontend se inscreve para atualiza√ß√µes em tempo real

#### **Fase 2: Scraping e Cria√ß√£o do Log**
- Edge Function faz requisi√ß√£o para MenuDino
- Extrai dados do HTML recebido
- **Cria registro em `import_logs` diretamente**
- Frontend recebe atualiza√ß√£o em tempo real

#### **Fase 3: Preview**
- Frontend recebe dados via subscription
- Exibe preview completo para usu√°rio
- Dados j√° est√£o estruturados e prontos

#### **Fase 4: Confirma√ß√£o**
- Usu√°rio confirma importa√ß√£o
- Frontend chama Edge Function para importar
- Sistema marca log como "importing"

#### **Fase 5: Importa√ß√£o**
- Edge Function l√™ dados do `import_logs`
- Cria registros nas tabelas finais
- Atualiza status para "import_success"
- Frontend recebe atualiza√ß√£o em tempo real

---

## üîÑ **4. Estados e Transi√ß√µes**

### **Diagrama de Estados**

```mermaid
stateDiagram-v2
    [*] --> SCRAPING: Frontend chama Edge Function
    
    SCRAPING --> PROCESSING: Edge Function extrai dados
    PROCESSING --> PREVIEW_READY: Edge Function cria log
    
    PREVIEW_READY --> PREVIEWING: Frontend recebe update
    PREVIEWING --> PREVIEW_READY: Usu√°rio volta para preview
    
    PREVIEW_READY --> IMPORTING: Frontend chama import
    IMPORTING --> IMPORT_SUCCESS: Edge Function importa dados
    IMPORTING --> IMPORT_FAILED: Erro na importa√ß√£o
    
    PREVIEW_READY --> CANCELLED: Usu√°rio cancela importa√ß√£o
    
    SCRAPING --> SCRAPING_FAILED: Erro no scraping
    SCRAPING_FAILED --> [*]: Falha final
    
    PROCESSING --> PROCESSING_FAILED: Erro no processamento
    PROCESSING_FAILED --> [*]: Falha final
    
    IMPORT_SUCCESS --> [*]: Importa√ß√£o finalizada
    IMPORT_FAILED --> PREVIEW_READY: Usu√°rio pode tentar novamente
    CANCELLED --> [*]: Importa√ß√£o cancelada
```

### **Descri√ß√£o dos Estados**

| Estado | Descri√ß√£o | Criado/Atualizado por | Dados Dispon√≠veis | A√ß√µes Poss√≠veis |
|--------|-----------|----------------------|-------------------|-----------------|
| `SCRAPING` | Fazendo scraping | Edge Function | URL sendo processada | Aguardar |
| `PROCESSING` | Processando dados | Edge Function | Dados extra√≠dos | Aguardar |
| `PREVIEW_READY` | Preview dispon√≠vel | Edge Function | Todos os dados extra√≠dos | Visualizar, confirmar, cancelar |
| `PREVIEWING` | Visualizando dados | Frontend | Dados carregados | Voltar, confirmar |
| `IMPORTING` | Importando dados | Edge Function | ID do log | Aguardar |
| `IMPORT_SUCCESS` | Importa√ß√£o conclu√≠da | Edge Function | Restaurante criado | Finalizar |
| `IMPORT_FAILED` | Falha na importa√ß√£o | Edge Function | Dados originais | Tentar novamente |
| `CANCELLED` | Importa√ß√£o cancelada | Frontend | Nenhum | Iniciar nova |
| `SCRAPING_FAILED` | Falha no scraping | Edge Function | Erro | Tentar novamente |
| `PROCESSING_FAILED` | Falha no processamento | Edge Function | Erro | Tentar novamente |

---

## ÔøΩÔøΩÔ∏è **5. Estrutura de Dados**

### **Tabela `import_logs`**

```sql
CREATE TABLE public.import_logs (
  -- Identifica√ß√£o
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id uuid REFERENCES public.profiles(id) ON DELETE CASCADE,
  restaurant_id uuid REFERENCES public.restaurants(id) ON DELETE SET NULL,
  
  -- Metadados b√°sicos
  url text NOT NULL,
  status text NOT NULL CHECK (status IN (
    'scraping', 'processing', 'preview_ready', 
    'importing', 'import_success', 'import_failed',
    'scraping_failed', 'processing_failed', 'cancelled'
  )),
  source text NOT NULL DEFAULT 'menudino',
  
  -- Dados extra√≠dos (completos para preview)
  scraped_data jsonb,
  
  -- Metadados de processamento
  error_message text,
  duration_ms integer,
  items_processed integer DEFAULT 0,
  items_total integer DEFAULT 0,
  categories_count integer DEFAULT 0,
  dishes_count integer DEFAULT 0,
  complements_count integer DEFAULT 0,
  
  -- Campos de auditoria
  metadata jsonb DEFAULT '{}',
  created_at timestamptz NOT NULL DEFAULT now(),
  updated_at timestamptz NOT NULL DEFAULT now(),
  
  -- Campos para controle de estado
  started_at timestamptz,
  completed_at timestamptz,
  retry_count integer DEFAULT 0
);
```

### **Estrutura do `scraped_data`**

```typescript
interface ScrapedData {
  restaurant: {
    name: string;
    cuisine_type?: string;
    address?: string;
    phone?: string;
    image_url?: string;
  };
  categories: string[];
  menu_items: {
    name: string;
    category: string;
    price: number;
    description?: string;
  }[];
  extraction_metadata: {
    html_length: number;
    extracted_at: string;
    processing_time_ms: number;
    extraction_quality_score?: number;
  };
}
```

---

## ‚öôÔ∏è **6. Implementa√ß√£o T√©cnica**

### **6.1 Background Tasks no Supabase Edge Functions**

O Supabase Edge Functions suporta background tasks usando `EdgeRuntime.waitUntil(promise)`. Esta funcionalidade permite:

- **Executar tarefas ass√≠ncronas** sem bloquear a resposta da requisi√ß√£o
- **Responder rapidamente** aos usu√°rios enquanto o processamento continua
- **Manter a inst√¢ncia da fun√ß√£o ativa** at√© que a promise seja resolvida

#### **Sintaxe Correta para Background Tasks**

```typescript
// ‚úÖ CORRETO: Usar EdgeRuntime.waitUntil para background tasks
EdgeRuntime.waitUntil(asyncLongRunningTask())

// ‚ùå INCORRETO: Usar await que bloqueia a resposta
await asyncLongRunningTask()
```

#### **Configura√ß√£o para Background Tasks Locais**

Para testar background tasks localmente, adicione ao `supabase/config.toml`:

```toml
[edge_runtime]
policy = "per_worker"
```

**‚ö†Ô∏è Nota**: Com `per_worker`, a fun√ß√£o n√£o recarrega automaticamente. √â necess√°rio reiniciar manualmente com `supabase functions serve`.

### **6.2 Edge Function com Hono (Atualizada)**

A Edge Function implementa o padr√£o de background tasks da seguinte forma:

1. **Cria√ß√£o Imediata do Log**: Cria registro em `import_logs` e retorna ID
2. **In√≠cio da Background Task**: Usa `EdgeRuntime.waitUntil()` para iniciar scraping
3. **Resposta Imediata**: Frontend recebe ID para iniciar subscription
4. **Processamento em Background**: Scraping e processamento continuam independentemente

#### **Estrutura da Edge Function**

A Edge Function √© organizada em tr√™s componentes principais:

1. **Rota `/scrape`**: Cria log e inicia background task
2. **Rota `/import`**: Processa importa√ß√£o final dos dados
3. **Fun√ß√µes auxiliares**: Gerenciamento de logs e processamento de dados

#### **Fluxo de Background Task**

```typescript
// 1. Criar registro imediatamente
const importLog = await createImportLog(url, userId, 'pending');

// 2. Iniciar background task (N√ÉO usar await)
EdgeRuntime.waitUntil(startBackgroundScraping(importLog.id, url, userId));

// 3. Retornar ID imediatamente
return c.json({ success: true, importLogId: importLog.id });
```

### **6.3 Cliente de Scraping Simplificado**

O frontend se torna um cliente simples que:

1. **Chama Edge Function** para iniciar importa√ß√£o
2. **Recebe ID do log** imediatamente
3. **Inicia subscription** para atualiza√ß√µes em tempo real
4. **Exibe progresso** conforme recebe atualiza√ß√µes

#### **Principais Mudan√ßas**

- **Remo√ß√£o de l√≥gica complexa**: Edge Function gerencia todo o processo
- **Retorno simplificado**: Apenas ID do log para subscription
- **Tratamento de erros**: Centralizado na Edge Function
- **Status tracking**: Via Supabase Realtime

---

## üîÑ **7. Fluxo de Opera√ß√µes**

### **7.1 Fluxo de Scraping (Cria√ß√£o + Background Task)**

```mermaid
flowchart TD
    A[Frontend chama Edge Function] --> B[Edge Function cria import_log]
    B --> C[Status: pending]
    C --> D[EdgeRuntime.waitUntil inicia background task]
    D --> E[Retorna importLogId imediatamente]
    E --> F[Frontend inicia subscription]
    F --> G[Background task roda independentemente]
    G --> H[Status: scraping]
    H --> I[Fazer fetch para MenuDino]
    I --> J[Extrair dados do HTML]
    J --> K[Status: preview_ready]
    K --> L[Frontend recebe update via Realtime]
```

### **7.2 Fluxo de Preview (Dados via Subscription)**

```mermaid
flowchart TD
    A[Subscription ativa] --> B[Receber update de preview_ready]
    B --> C[Carregar dados do import_logs]
    C --> D[Exibir dados estruturados]
    D --> E[Usu√°rio visualiza]
    E --> F{Confirmar?}
    F -->|Sim| G[Chamar Edge Function para importar]
    F -->|N√£o| H[Cancelar ou editar]
```

### **7.3 Fluxo de Importa√ß√£o (Edge Function Controla Tudo)**

```mermaid
flowchart TD
    A[Frontend chama import] --> B[Edge Function atualiza status]
    B --> C[Status: importing]
    C --> D[Ler scraped_data do log]
    D --> E[Criar restaurante, categorias, pratos]
    E --> F[Status: import_success]
    F --> G[Frontend recebe update via Realtime]
```

### **7.4 Vantagens da Nova Abordagem**

1. **‚ö° Responsividade**: Frontend recebe ID imediatamente
2. **üîÑ Background Processing**: Scraping roda independentemente via `EdgeRuntime.waitUntil`
3. **‚ö° UX Melhorada**: Usu√°rio v√™ progresso em tempo real
4. **üîß Arquitetura Limpa**: Separa√ß√£o clara entre cria√ß√£o e processamento
5. **üìä Status Tracking**: Frontend pode mostrar progresso desde o in√≠cio
6. **üîÑ Realtime Updates**: Atualiza√ß√µes autom√°ticas via Supabase
7. **üõ°Ô∏è Confiabilidade**: Edge Function controla todo o fluxo
8. **üìà Escalabilidade**: Background tasks n√£o bloqueiam o frontend

### **7.5 Compara√ß√£o: Antes vs Depois**

#### **Antes (S√≠ncrono)**
1. Frontend chama Edge Function
2. Edge Function faz scraping completo
3. Edge Function retorna dados + status
4. Frontend exibe resultado

#### **Depois (Ass√≠ncrono + Background Task)**
1. Frontend chama Edge Function
2. **Edge Function cria log e retorna ID imediatamente**
3. **Frontend inicia subscription com o ID**
4. **Edge Function inicia background task para scraping**
5. **Frontend recebe atualiza√ß√µes em tempo real**
6. **Usu√°rio v√™ progresso desde o in√≠cio**

Esta abordagem torna o sistema muito mais responsivo e oferece uma experi√™ncia de usu√°rio superior, pois o usu√°rio v√™ o progresso em tempo real desde o momento que clica no bot√£o.

---

## üö® **8. Tratamento de Erros**

### **8.1 Tipos de Erro e Estados**

| Tipo de Erro | Causa | Estado Resultante | A√ß√£o do Sistema |
|--------------|-------|-------------------|-----------------|
| **CORS Error** | Pol√≠tica de seguran√ßa do navegador | `scraping_failed` | Log de erro, usu√°rio pode tentar novamente |
| **Network Error** | Falha na conex√£o | `scraping_failed` | Log de erro, sugest√£o de retry |
| **Parse Error** | HTML malformado | `processing_failed` | Log de erro, an√°lise do HTML |
| **Validation Error** | Dados inv√°lidos | `processing_failed` | Log de erro, sugest√£o de corre√ß√£o |
| **Database Error** | Falha no banco | `import_failed` | Rollback autom√°tico, log de erro |

### **8.2 Estrat√©gias de Recupera√ß√£o**

#### **Retry Autom√°tico para Falhas de Rede**
- **Exponencial Backoff**: Intervalos crescentes entre tentativas
- **M√°ximo de 3 tentativas** para evitar loops infinitos
- **Log detalhado** de cada tentativa para debugging

#### **Fallback para Dados Parciais**
- **Salvar dados v√°lidos** mesmo com falhas parciais
- **Marcar campos problem√°ticos** para revis√£o manual
- **Permitir importa√ß√£o parcial** com avisos ao usu√°rio

#### **Notifica√ß√£o de Erros**
- **Toast notifications** para erros cr√≠ticos
- **Logs detalhados** no console para desenvolvedores
- **Sugest√µes de a√ß√£o** para o usu√°rio

---

## üìä **9. Monitoramento e Logs**

### **9.1 Estrutura de Logs**

O sistema implementa logging em m√∫ltiplas camadas:

#### **Logs da Edge Function**
- **Console logs** para debugging em tempo real
- **Structured logging** com timestamps e contextos
- **Error tracking** com stack traces completos

#### **Logs do Frontend**
- **User actions** para auditoria de uso
- **Performance metrics** para otimiza√ß√£o
- **Error boundaries** para captura de falhas

#### **Logs do Banco de Dados**
- **Audit trail** completo em `import_logs`
- **Performance metrics** (dura√ß√£o, itens processados)
- **Status transitions** para debugging

### **9.2 M√©tricas de Performance**

#### **Tempo de Resposta**
- **Tempo at√© primeiro byte**: Cria√ß√£o do log
- **Tempo de scraping**: Processamento da p√°gina
- **Tempo total**: Da cria√ß√£o at√© importa√ß√£o final

#### **Taxa de Sucesso**
- **Scraping success rate**: % de p√°ginas processadas com sucesso
- **Import success rate**: % de dados importados corretamente
- **Error distribution**: An√°lise dos tipos de erro mais comuns

#### **Uso de Recursos**
- **Memory usage**: Consumo de mem√≥ria durante processamento
- **CPU usage**: Utiliza√ß√£o de processamento
- **Network calls**: N√∫mero de requisi√ß√µes externas

---

## üöÄ **10. Deploy e Configura√ß√£o**

### **10.1 Deploy da Edge Function**

#### **Desenvolvimento Local**
```bash
# 1. Navegar para o diret√≥rio da fun√ß√£o
cd supabase/functions/scrape-menudino

# 2. Configurar vari√°veis de ambiente
cp .env.example .env.local
# Editar .env.local com suas configura√ß√µes

# 3. Deploy para desenvolvimento local
supabase functions serve scrape-menudino --env-file .env.local

# 4. Testar localmente
curl -X POST http://localhost:54321/functions/v1/scrape-menudino/scrape \
  -H "Content-Type: application/json" \
  -d '{"url": "https://test.menudino.com.br/"}'
```

#### **Produ√ß√£o**
```bash
# 1. Deploy para produ√ß√£o
supabase functions deploy scrape-menudino --project-ref YOUR_PROJECT_ID

# 2. Verificar status
supabase functions list --project-ref YOUR_PROJECT_ID

# 3. Ver logs em produ√ß√£o
supabase functions logs scrape-menudino --project-ref YOUR_PROJECT_ID
```

### **10.2 Configura√ß√£o de Ambiente**

#### **Vari√°veis Obrigat√≥rias**
```bash
# .env.local / .env.production
SUPABASE_URL=http://localhost:54321  # ou URL de produ√ß√£o
SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key
```

#### **Vari√°veis Opcionais**
```bash
# Configura√ß√µes de performance
MAX_RETRIES=3
SCRAPING_TIMEOUT=30000
MAX_CONCURRENT_SCRAPES=5

# Configura√ß√µes de logging
LOG_LEVEL=info
ENABLE_DEBUG_LOGS=true
```

### **10.3 Configura√ß√£o do Supabase**

#### **config.toml para Background Tasks**
```toml
[functions.scrape-menudino]
verify_jwt = false
import_map = "./deno.json"

[edge_runtime]
policy = "per_worker"  # Necess√°rio para background tasks

[functions.scrape-menudino.environment]
ENVIRONMENT = "production"
LOG_LEVEL = "info"
MAX_RETRIES = "3"
SCRAPING_TIMEOUT = "30000"
```

---

## üß™ **11. Testes e Valida√ß√£o**

### **11.1 Estrat√©gia de Testes**

#### **Testes Unit√°rios**
- **Fun√ß√µes de extra√ß√£o**: Valida√ß√£o de parsing de HTML
- **Fun√ß√µes de valida√ß√£o**: Verifica√ß√£o de dados extra√≠dos
- **Fun√ß√µes de banco**: Opera√ß√µes CRUD em `import_logs`

#### **Testes de Integra√ß√£o**
- **Edge Function completa**: End-to-end do fluxo de scraping
- **Supabase Realtime**: Verifica√ß√£o de atualiza√ß√µes em tempo real
- **Database operations**: Cria√ß√£o e atualiza√ß√£o de registros

#### **Testes de Performance**
- **Tempo de resposta**: Lat√™ncia da cria√ß√£o do log
- **Background task duration**: Dura√ß√£o do scraping
- **Concurrent requests**: M√∫ltiplas importa√ß√µes simult√¢neas

### **11.2 Cen√°rios de Teste**

#### **Cen√°rios de Sucesso**
1. **URL v√°lida do MenuDino**: Scraping completo e importa√ß√£o
2. **M√∫ltiplas categorias**: Processamento de menus complexos
3. **Dados completos**: Restaurante, categorias e pratos
4. **Importa√ß√£o parcial**: Dados com campos opcionais

#### **Cen√°rios de Erro**
1. **URL inv√°lida**: Tratamento de URLs malformadas
2. **P√°gina n√£o encontrada**: HTTP 404 e outros c√≥digos de erro
3. **HTML malformado**: Parsing de p√°ginas com estrutura inv√°lida
4. **Timeout de rede**: Falhas de conectividade
5. **Erro de banco**: Falhas na persist√™ncia de dados

#### **Cen√°rios de Edge Case**
1. **P√°ginas muito grandes**: HTML com muitos elementos
2. **Caracteres especiais**: Nomes com acentos e s√≠mbolos
3. **Pre√ßos variados**: Diferentes formatos de pre√ßo
4. **Categorias aninhadas**: Estruturas hier√°rquicas complexas

---

## üîß **12. Manuten√ß√£o e Troubleshooting**

### **12.1 Problemas Comuns**

#### **Edge Function n√£o responde**
**Sintomas**: Timeout ou erro 500
**Causas**: 
- Background task travada
- Memory leak
- Timeout de rede

**Solu√ß√µes**:
```bash
# Verificar logs
supabase functions logs scrape-menudino

# Verificar status
supabase functions list

# Reiniciar fun√ß√£o
supabase functions serve scrape-menudino --env-file .env.local
```

#### **Background task n√£o executa**
**Sintomas**: Status fica em "pending" indefinidamente
**Causas**:
- Configura√ß√£o incorreta de `edge_runtime.policy`
- Erro na fun√ß√£o `startBackgroundScraping`
- Inst√¢ncia da fun√ß√£o terminada prematuramente

**Solu√ß√µes**:
```toml
# Verificar config.toml
[edge_runtime]
policy = "per_worker"

# Verificar logs da fun√ß√£o
supabase functions logs scrape-menudino --follow
```

#### **Dados n√£o sendo salvos**
**Sintomas**: Preview n√£o aparece ou dados incompletos
**Causas**:
- Falha na cria√ß√£o do log inicial
- Erro na atualiza√ß√£o do status
- Problema de permiss√µes no banco

**Solu√ß√µes**:
```sql
-- Verificar se a tabela import_logs existe
SELECT * FROM information_schema.tables 
WHERE table_name = 'import_logs';

-- Verificar pol√≠ticas RLS
SELECT * FROM pg_policies 
WHERE tablename = 'import_logs';

-- Verificar dados na tabela
SELECT * FROM import_logs ORDER BY created_at DESC LIMIT 5;
```

### **12.2 Monitoramento de Performance**

#### **M√©tricas de Sa√∫de**
- **Uptime**: Disponibilidade da Edge Function
- **Response time**: Tempo de resposta m√©dio
- **Error rate**: Taxa de erros por per√≠odo
- **Success rate**: Taxa de sucesso das importa√ß√µes

#### **Alertas Autom√°ticos**
- **High error rate**: >5% de erros em 5 minutos
- **Slow response**: >30 segundos para cria√ß√£o de log
- **Background task failure**: Falhas consecutivas de scraping
- **Database errors**: Problemas de conex√£o ou permiss√µes

### **12.3 Limpeza e Manuten√ß√£o**

#### **Limpeza de Logs Antigos**
```sql
-- Limpar logs antigos (manter apenas √∫ltimos 30 dias)
DELETE FROM import_logs 
WHERE created_at < NOW() - INTERVAL '30 days'
AND status IN ('import_success', 'cancelled');

-- Limpar logs com falha (manter apenas √∫ltimos 7 dias)
DELETE FROM import_logs 
WHERE created_at < NOW() - INTERVAL '7 days'
AND status IN ('scraping_failed', 'processing_failed', 'import_failed');
```

#### **Otimiza√ß√£o de Performance**
- **√çndices de banco**: Para consultas frequentes
- **Cache de dados**: Para URLs frequentemente acessadas
- **Rate limiting**: Para evitar sobrecarga do MenuDino
- **Connection pooling**: Para opera√ß√µes de banco eficientes

---

## üìù **13. Considera√ß√µes Finais**

### **13.1 Benef√≠cios da Implementa√ß√£o**

O sistema de importa√ß√£o MenuDino com Edge Functions oferece:

1. **üöÄ Performance Superior**: Background tasks n√£o bloqueiam o frontend
2. **‚ö° Experi√™ncia em Tempo Real**: Atualiza√ß√µes via Supabase Realtime
3. **üîß Arquitetura Robusta**: Separa√ß√£o clara de responsabilidades
4. **üìä Monitoramento Completo**: Logs e m√©tricas detalhadas
5. **üõ°Ô∏è Tratamento de Erros**: Recupera√ß√£o autom√°tica e fallbacks
6. **üìà Escalabilidade**: Suporte a m√∫ltiplas importa√ß√µes simult√¢neas

### **13.2 Limita√ß√µes e Considera√ß√µes**

#### **Limita√ß√µes T√©cnicas**
- **Timeout de Edge Functions**: M√°ximo de 60 segundos para background tasks
- **Memory limits**: Restri√ß√µes de mem√≥ria para processamento de HTML
- **Network reliability**: Depend√™ncia da estabilidade do MenuDino

#### **Considera√ß√µes de Neg√≥cio**
- **Rate limiting**: Respeitar limites de requisi√ß√µes ao MenuDino
- **Data quality**: Valida√ß√£o de dados extra√≠dos antes da importa√ß√£o
- **User experience**: Feedback claro sobre progresso e erros

### **13.3 Roadmap Futuro**

#### **Melhorias Planejadas**
1. **Cache inteligente**: Evitar re-scraping de URLs recentes
2. **Batch processing**: Processamento em lote de m√∫ltiplas URLs
3. **Machine learning**: Detec√ß√£o autom√°tica de padr√µes de menu
4. **Multi-language support**: Suporte a diferentes idiomas
5. **Advanced validation**: Valida√ß√£o mais sofisticada de dados

#### **Integra√ß√µes Futuras**
1. **Webhook notifications**: Notifica√ß√µes para sistemas externos
2. **Analytics dashboard**: M√©tricas avan√ßadas de uso
3. **API p√∫blica**: Endpoints para integra√ß√£o com terceiros
4. **Mobile app**: Aplicativo m√≥vel para importa√ß√£o

---

## üìö **14. Refer√™ncias e Recursos**

### **14.1 Documenta√ß√£o Oficial**
- [Supabase Edge Functions](https://supabase.com/docs/guides/functions)
- [Background Tasks](https://supabase.com/docs/guides/functions/background-tasks)
- [Supabase Realtime](https://supabase.com/docs/guides/realtime)
- [Row Level Security](https://supabase.com/docs/guides/auth/row-level-security)

### **14.2 Ferramentas e Bibliotecas**
- [Hono Framework](https://hono.dev): Framework web para Edge Functions
- [Deno Runtime](https://deno.land): Runtime JavaScript/TypeScript
- [PostgreSQL](https://www.postgresql.org): Banco de dados relacional

### **14.3 Comunidade e Suporte**
- [Supabase Discord](https://discord.supabase.com): Comunidade oficial
- [GitHub Issues](https://github.com/supabase/supabase/issues): Reportar bugs
- [Stack Overflow](https://stackoverflow.com/questions/tagged/supabase): Perguntas e respostas

---

**Nota**: Esta documenta√ß√£o assume familiaridade com o Supabase, Edge Functions e conceitos de desenvolvimento web. Recomenda-se consultar a [documenta√ß√£o oficial do Supabase](https://supabase.com/docs) para informa√ß√µes adicionais.

---

*Documenta√ß√£o gerada em: Janeiro 2025*  
*Vers√£o: 1.0.0*  
*√öltima atualiza√ß√£o: Sistema de Background Tasks com EdgeRuntime.waitUntil*
